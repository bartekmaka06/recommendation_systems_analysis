{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d9a3964",
   "metadata": {},
   "source": [
    "Przypadki testowe:\n",
    "\n",
    "dla małej i dużej liczby filmów\n",
    "\n",
    "dla małej i dużej liczby użytkowników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3689121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from time import time\n",
    "import psutil\n",
    "from surprise import SVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "ml_rating_path = 'dane/ml-20m/ml-20m/ratings.csv'\n",
    "ml_movies_path = 'dane/ml-20m/ml-20m/movies.csv'\n",
    "ml_tags_path = 'dane/ml-20m/ml-20m/tags.csv'\n",
    "\n",
    "# Funkcja do ograniczenia danych\n",
    "def reduce_ratings(data, reduction_rate):\n",
    "    #Usuwa określony procent ocen z danych.\n",
    "    data = data.sample(frac=(1 - reduction_rate), random_state=42).reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "# Funkcja do oceny metryk\n",
    "def calculate_metrics(predictions, threshold=4.0):\n",
    "    #Oblicza precision, recall i F1-score.\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for pred in predictions:\n",
    "        true_rating = pred.r_ui\n",
    "        predicted_rating = pred.est\n",
    "        y_true.append(1 if true_rating >= threshold else 0)\n",
    "        y_pred.append(1 if predicted_rating >= threshold else 0)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b88953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Size: 100, Reduction Rate: 0.1\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "   user_size  reduction_rate  precision    recall  f1_score    time s  \\\n",
      "0        100             0.1   0.668719  0.384289   0.48809  0.103876   \n",
      "\n",
      "   memory_usage %  cpu_usage %  \n",
      "0            67.1         53.6  \n"
     ]
    }
   ],
   "source": [
    "#Eksperyment: Algorytm Collaborative filtering oparty na pamięci\n",
    "\n",
    "# Parametry eksperymentu\n",
    "user_sizes = [100] #100, 10000, 100000\n",
    "reduction_rates = [0.5]  # Usuwanie 10%, 25%, 50% danych  0.25, 0.5\n",
    "\n",
    "# Wczytanie danych z MovieLens\n",
    "df = pd.read_csv(ml_rating_path)  # Zmień na odpowiednią ścieżkę\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# Eksperyment\n",
    "results = []\n",
    "for user_size in user_sizes:\n",
    "    # Ogranicz liczbę użytkowników\n",
    "    sampled_users = df['userId'].unique()[:user_size]\n",
    "    filtered_data = df[df['userId'].isin(sampled_users)]\n",
    "    \n",
    "    for reduction_rate in reduction_rates:\n",
    "        print(f\"User Size: {user_size}, Reduction Rate: {reduction_rate}\")\n",
    "        reduced_data = reduce_ratings(filtered_data, reduction_rate)\n",
    "        \n",
    "        # Przygotowanie danych do modelu\n",
    "        data = Dataset.load_from_df(reduced_data[['userId', 'movieId', 'rating']], reader)\n",
    "        trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
    "        \n",
    "        # Tworzenie modelu Collaborative Filtering opartego na użytkownikach\n",
    "        sim_options = {'name': 'cosine', 'user_based': True}\n",
    "        model = KNNBasic(sim_options=sim_options)\n",
    "        \n",
    "        # Pomiar czasu i zasobów\n",
    "        start_time = time()\n",
    "        model.fit(trainset)\n",
    "        predictions = model.test(testset)\n",
    "        end_time = time()\n",
    "        \n",
    "        # Obliczenie metryk\n",
    "        precision, recall, f1 = calculate_metrics(predictions)\n",
    "        \n",
    "        # Pomiar zasobów\n",
    "        memory_usage = psutil.virtual_memory().percent\n",
    "        cpu_usage = psutil.cpu_percent(interval=0.1)\n",
    "        \n",
    "        # Zapis wyników\n",
    "        results.append({\n",
    "            'user_size': user_size,\n",
    "            'reduction_rate': reduction_rate,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'time s': end_time - start_time,\n",
    "            'memory_usage %': memory_usage,\n",
    "            'cpu_usage %': cpu_usage\n",
    "        })\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44941146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Size: 100, Reduction Rate: 0.1\n",
      "User Size: 100, Reduction Rate: 0.25\n",
      "User Size: 100, Reduction Rate: 0.5\n",
      "   user_size  reduction_rate  precision    recall  f1_score      time  \\\n",
      "0        100            0.10   0.804702  0.314933  0.452696  0.120677   \n",
      "1        100            0.25   0.796875  0.309896  0.446250  0.092723   \n",
      "2        100            0.50   0.774809  0.262274  0.391892  0.047433   \n",
      "\n",
      "   memory_usage  cpu_usage  \n",
      "0          64.7       42.9  \n",
      "1          64.6       17.9  \n",
      "2          64.5        3.6  \n"
     ]
    }
   ],
   "source": [
    "#Eksperyment: Algorytm Collaborative filtering oparty na modelu\n",
    "\n",
    "# Parametry eksperymentu\n",
    "user_sizes = [100]  # Mały zbiór użytkowników (można rozszerzyć na 10000, 100000)\n",
    "reduction_rates = [0.1, 0.25, 0.5]  # Ograniczenie danych (np. 10%, 25%, 50%)\n",
    "\n",
    "# Wczytanie danych z MovieLens\n",
    "df = pd.read_csv(ml_rating_path)\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# Eksperyment\n",
    "results = []\n",
    "for user_size in user_sizes:\n",
    "    # Ogranicz liczbę użytkowników\n",
    "    sampled_users = df['userId'].unique()[:user_size]\n",
    "    filtered_data = df[df['userId'].isin(sampled_users)]\n",
    "    \n",
    "    for reduction_rate in reduction_rates:\n",
    "        print(f\"User Size: {user_size}, Reduction Rate: {reduction_rate}\")\n",
    "        reduced_data = reduce_ratings(filtered_data, reduction_rate)\n",
    "        \n",
    "        # Przygotowanie danych do modelu\n",
    "        data = Dataset.load_from_df(reduced_data[['userId', 'movieId', 'rating']], reader)\n",
    "        trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
    "        \n",
    "        # Tworzenie modelu Collaborative Filtering opartego na modelu (SVD)\n",
    "        model = SVD()\n",
    "        \n",
    "        # Pomiar czasu i zasobów\n",
    "        start_time = time()\n",
    "        model.fit(trainset)\n",
    "        predictions = model.test(testset)\n",
    "        end_time = time()\n",
    "        \n",
    "        # Obliczenie metryk\n",
    "        precision, recall, f1 = calculate_metrics(predictions)\n",
    "        \n",
    "        # Pomiar zasobów\n",
    "        memory_usage = psutil.virtual_memory().percent\n",
    "        cpu_usage = psutil.cpu_percent(interval=0.1)\n",
    "        \n",
    "        # Zapis wyników\n",
    "        results.append({\n",
    "            'user_size': user_size,\n",
    "            'reduction_rate': reduction_rate,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'time': end_time - start_time,\n",
    "            'memory_usage': memory_usage,\n",
    "            'cpu_usage': cpu_usage\n",
    "        })\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb2afff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Size: 10, Movie Size: 50\n",
      "User Size: 10, Movie Size: 1000\n",
      "User Size: 10, Movie Size: 10000\n",
      "   user_size  movie_size  precision    recall  f1_score       time  \\\n",
      "0         10          50      0.000  0.000000  0.000000   0.005981   \n",
      "1         10        1000      0.000  0.000000  0.000000   0.110673   \n",
      "2         10       10000      0.002  0.013514  0.003484  15.964484   \n",
      "\n",
      "   memory_usage  cpu_usage  \n",
      "0          52.8        4.2  \n",
      "1          52.8       35.7  \n",
      "2          52.8        0.0  \n"
     ]
    }
   ],
   "source": [
    "#Eksperyment: Algorytm Content-based filtering\n",
    "from sklearn.model_selection import train_test_split as sklearn_train_test_split\n",
    "\n",
    "# Funkcja do oceny metryk\n",
    "def evaluate_content_based(recommendations, test_data, threshold=0.0):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for user_id, recommended_movies in recommendations.items():\n",
    "        test_movies = test_data[test_data['userId'] == user_id]\n",
    "        test_movies = test_movies[test_movies['rating'] >= threshold]['movieId'].values\n",
    "\n",
    "        true_set = set(test_movies)\n",
    "        pred_set = set(movie for movie, _ in recommended_movies)\n",
    "\n",
    "        for movie in pred_set:\n",
    "            y_pred.append(1)\n",
    "            y_true.append(1 if movie in true_set else 0)\n",
    "\n",
    "        for movie in true_set - pred_set:\n",
    "            y_true.append(1)\n",
    "            y_pred.append(0)\n",
    "\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Algorytm Content-Based Filtering\n",
    "def content_based_filtering(data, movie_df, use_tags=True):\n",
    "    # Połączenie tagów i gatunków w jedną kolumnę\n",
    "    movie_df['combined_features'] = movie_df['tags'].fillna('') + ' ' + movie_df['genres'].fillna('')\n",
    "\n",
    "    # TF-IDF na połączonych cechach\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(movie_df['combined_features'])\n",
    "\n",
    "    # Macierz podobieństwa kosinusowego\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "    recommendations = {}\n",
    "    for user_id in data['userId'].unique():\n",
    "        rated_movies = data[data['userId'] == user_id]\n",
    "        user_ratings = rated_movies.set_index('movieId')['rating']\n",
    "\n",
    "        movie_scores = {}\n",
    "        for movie_id, rating in user_ratings.items():\n",
    "            if movie_id - 1 < len(cosine_sim):  # Sprawdzenie zakresu\n",
    "                similar_movies = cosine_sim[movie_id - 1]\n",
    "                for idx, score in enumerate(similar_movies):\n",
    "                    if movie_id != idx + 1 and idx + 1 not in rated_movies['movieId'].values:\n",
    "                        movie_scores[idx + 1] = movie_scores.get(idx + 1, 0) + score * rating\n",
    "\n",
    "        sorted_movie_scores = sorted(movie_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        recommendations[user_id] = sorted_movie_scores[:100]\n",
    "    return recommendations\n",
    "\n",
    "ratings = pd.read_csv(ml_rating_path)\n",
    "movies = pd.read_csv(ml_movies_path)\n",
    "tags = pd.read_csv(ml_tags_path)\n",
    "\n",
    "# Dodanie tagów do filmów\n",
    "tags['tag'] = tags['tag'].fillna('').astype(str)\n",
    "tag_groups = tags.groupby('movieId')['tag'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "movies = movies.merge(tag_groups, on='movieId', how='left')\n",
    "movies['tags'] = movies['tag']  # Kolumna z tagami\n",
    "\n",
    "# Parametry eksperymentu\n",
    "user_sizes = [10]  # Liczba użytkowników\n",
    "movie_sizes = [50, 1000, 10000]  # Liczba filmów do analizy\n",
    "results = []\n",
    "\n",
    "# Eksperyment\n",
    "for user_size in user_sizes:\n",
    "    sampled_users = ratings['userId'].unique()[:user_size]\n",
    "    filtered_data = ratings[ratings['userId'].isin(sampled_users)]\n",
    "\n",
    "    for movie_size in movie_sizes:\n",
    "        sampled_movies = movies.sample(n=movie_size, random_state=42)\n",
    "        filtered_data_movies = filtered_data[filtered_data['movieId'].isin(sampled_movies['movieId'])]\n",
    "\n",
    "        print(f\"User Size: {user_size}, Movie Size: {movie_size}\")\n",
    "        \n",
    "        # Podział na dane treningowe i testowe\n",
    "        train_data, test_data = sklearn_train_test_split(filtered_data_movies, test_size=0.4, random_state=42)\n",
    "\n",
    "        # Uruchomienie algorytmu Content-Based Filtering\n",
    "        start_time = time()\n",
    "        recommendations = content_based_filtering(train_data, sampled_movies, use_tags=True)\n",
    "        elapsed_time = time() - start_time\n",
    "\n",
    "        # Obliczanie metryk\n",
    "        precision, recall, f1 = evaluate_content_based(recommendations, test_data)\n",
    "\n",
    "        # Pomiar zasobów\n",
    "        memory_usage = psutil.virtual_memory().percent\n",
    "        cpu_usage = psutil.cpu_percent(interval=0.1)\n",
    "\n",
    "        # Zapis wyników\n",
    "        results.append({\n",
    "            'user_size': user_size,\n",
    "            'movie_size': movie_size,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'time': elapsed_time,\n",
    "            'memory_usage': memory_usage,\n",
    "            'cpu_usage': cpu_usage\n",
    "        })\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e042a2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with user_sample_size=10 and movie_sample_size=100\n",
      "actual_movies56\n",
      "recommended_movies10\n",
      "actual_movies19\n",
      "recommended_movies10\n",
      "actual_movies16\n",
      "recommended_movies10\n",
      "actual_movies33\n",
      "recommended_movies10\n",
      "actual_movies17\n",
      "recommended_movies10\n",
      "actual_movies6\n",
      "recommended_movies10\n",
      "actual_movies15\n",
      "recommended_movies10\n",
      "actual_movies8\n",
      "recommended_movies10\n",
      "actual_movies3\n",
      "recommended_movies10\n",
      "actual_movies11\n",
      "recommended_movies10\n",
      "Precision: 0.46, Recall: 1.0, F1: 0.6301369863013699, Memory Usage: 5792.2421875 MB\n",
      "Running experiment with user_sample_size=10 and movie_sample_size=5000\n",
      "actual_movies47\n",
      "recommended_movies10\n",
      "actual_movies18\n",
      "recommended_movies10\n",
      "actual_movies14\n",
      "recommended_movies10\n",
      "actual_movies52\n",
      "recommended_movies10\n",
      "actual_movies30\n",
      "recommended_movies10\n",
      "actual_movies19\n",
      "recommended_movies10\n",
      "actual_movies28\n",
      "recommended_movies10\n",
      "actual_movies15\n",
      "recommended_movies10\n",
      "actual_movies13\n",
      "recommended_movies10\n",
      "actual_movies77\n",
      "recommended_movies10\n",
      "Precision: 0.55, Recall: 1.0, F1: 0.7096774193548387, Memory Usage: 5792.26171875 MB\n",
      "Running experiment with user_sample_size=10 and movie_sample_size=20000\n",
      "actual_movies5\n",
      "recommended_movies10\n",
      "actual_movies6\n",
      "recommended_movies10\n",
      "actual_movies41\n",
      "recommended_movies10\n",
      "actual_movies32\n",
      "recommended_movies10\n",
      "actual_movies90\n",
      "recommended_movies10\n",
      "actual_movies5\n",
      "recommended_movies10\n",
      "actual_movies4\n",
      "recommended_movies10\n",
      "actual_movies15\n",
      "recommended_movies10\n",
      "actual_movies81\n",
      "recommended_movies10\n",
      "actual_movies6\n",
      "recommended_movies10\n",
      "Precision: 0.53, Recall: 1.0, F1: 0.6928104575163399, Memory Usage: 5792.26953125 MB\n",
      "Running experiment with user_sample_size=100 and movie_sample_size=100\n",
      "actual_movies5\n",
      "recommended_movies10\n",
      "actual_movies12\n",
      "recommended_movies10\n",
      "actual_movies15\n",
      "recommended_movies10\n",
      "actual_movies23\n",
      "recommended_movies10\n",
      "actual_movies35\n",
      "recommended_movies10\n",
      "actual_movies44\n",
      "recommended_movies10\n",
      "actual_movies68\n",
      "recommended_movies10\n",
      "actual_movies14\n",
      "recommended_movies10\n",
      "actual_movies192\n",
      "recommended_movies10\n",
      "actual_movies1\n",
      "recommended_movies10\n",
      "actual_movies5\n",
      "recommended_movies10\n",
      "actual_movies48\n",
      "recommended_movies10\n",
      "actual_movies160\n",
      "recommended_movies10\n",
      "actual_movies29\n",
      "recommended_movies10\n",
      "actual_movies9\n",
      "recommended_movies10\n",
      "actual_movies13\n",
      "recommended_movies10\n",
      "actual_movies11\n",
      "recommended_movies10\n",
      "actual_movies16\n",
      "recommended_movies10\n",
      "actual_movies16\n",
      "recommended_movies10\n",
      "actual_movies10\n",
      "recommended_movies10\n",
      "actual_movies3\n",
      "recommended_movies10\n",
      "actual_movies10\n",
      "recommended_movies10\n",
      "actual_movies10\n",
      "recommended_movies10\n",
      "actual_movies56\n",
      "recommended_movies10\n",
      "actual_movies61\n",
      "recommended_movies10\n",
      "actual_movies1\n",
      "recommended_movies10\n",
      "actual_movies4\n",
      "recommended_movies10\n",
      "actual_movies61\n",
      "recommended_movies10\n",
      "actual_movies3\n",
      "recommended_movies10\n",
      "actual_movies9\n",
      "recommended_movies10\n",
      "actual_movies10\n",
      "recommended_movies10\n",
      "actual_movies16\n",
      "recommended_movies10\n",
      "actual_movies44\n",
      "recommended_movies10\n",
      "actual_movies55\n",
      "recommended_movies10\n",
      "actual_movies25\n",
      "recommended_movies10\n",
      "actual_movies3\n",
      "recommended_movies10\n",
      "actual_movies10\n",
      "recommended_movies10\n",
      "actual_movies17\n",
      "recommended_movies10\n",
      "actual_movies12\n",
      "recommended_movies10\n",
      "actual_movies9\n",
      "recommended_movies10\n",
      "actual_movies6\n",
      "recommended_movies10\n",
      "actual_movies18\n",
      "recommended_movies10\n",
      "actual_movies79\n",
      "recommended_movies10\n",
      "actual_movies12\n",
      "recommended_movies10\n",
      "actual_movies18\n",
      "recommended_movies10\n",
      "actual_movies6\n",
      "recommended_movies10\n",
      "actual_movies8\n",
      "recommended_movies10\n",
      "actual_movies12\n",
      "recommended_movies10\n",
      "actual_movies24\n",
      "recommended_movies10\n",
      "actual_movies17\n",
      "recommended_movies10\n",
      "actual_movies6\n",
      "recommended_movies10\n",
      "actual_movies5\n",
      "recommended_movies10\n",
      "actual_movies17\n",
      "recommended_movies10\n",
      "actual_movies95\n",
      "recommended_movies10\n",
      "actual_movies33\n",
      "recommended_movies10\n",
      "actual_movies105\n",
      "recommended_movies10\n",
      "actual_movies17\n",
      "recommended_movies10\n",
      "actual_movies282\n",
      "recommended_movies10\n",
      "actual_movies22\n",
      "recommended_movies10\n",
      "actual_movies11\n",
      "recommended_movies10\n",
      "actual_movies13\n",
      "recommended_movies10\n",
      "actual_movies49\n",
      "recommended_movies10\n",
      "actual_movies63\n",
      "recommended_movies10\n",
      "actual_movies14\n",
      "recommended_movies10\n",
      "actual_movies3\n",
      "recommended_movies10\n",
      "actual_movies4\n",
      "recommended_movies10\n",
      "actual_movies10\n",
      "recommended_movies10\n",
      "actual_movies15\n",
      "recommended_movies10\n",
      "actual_movies81\n",
      "recommended_movies10\n",
      "actual_movies49\n",
      "recommended_movies10\n",
      "actual_movies41\n",
      "recommended_movies10\n",
      "actual_movies13\n",
      "recommended_movies10\n",
      "actual_movies34\n",
      "recommended_movies10\n",
      "actual_movies16\n",
      "recommended_movies10\n",
      "actual_movies3\n",
      "recommended_movies10\n",
      "actual_movies18\n",
      "recommended_movies10\n",
      "actual_movies14\n",
      "recommended_movies10\n",
      "actual_movies4\n",
      "recommended_movies10\n",
      "actual_movies5\n",
      "recommended_movies10\n",
      "actual_movies13\n",
      "recommended_movies10\n",
      "actual_movies7\n",
      "recommended_movies10\n",
      "actual_movies96\n",
      "recommended_movies10\n",
      "actual_movies10\n",
      "recommended_movies10\n",
      "actual_movies4\n",
      "recommended_movies10\n",
      "actual_movies14\n",
      "recommended_movies10\n",
      "actual_movies14\n",
      "recommended_movies10\n",
      "actual_movies11\n",
      "recommended_movies10\n",
      "actual_movies5\n",
      "recommended_movies10\n",
      "actual_movies25\n",
      "recommended_movies10\n",
      "actual_movies16\n",
      "recommended_movies10\n",
      "actual_movies22\n",
      "recommended_movies10\n",
      "actual_movies16\n",
      "recommended_movies10\n",
      "actual_movies72\n",
      "recommended_movies10\n",
      "actual_movies14\n",
      "recommended_movies10\n",
      "actual_movies8\n",
      "recommended_movies10\n",
      "actual_movies118\n",
      "recommended_movies10\n",
      "actual_movies40\n",
      "recommended_movies10\n",
      "actual_movies18\n",
      "recommended_movies10\n",
      "actual_movies23\n",
      "recommended_movies10\n",
      "actual_movies2\n",
      "recommended_movies10\n",
      "Precision: 0.474, Recall: 1.0, F1: 0.6431478968792401, Memory Usage: 5792.34375 MB\n",
      "Running experiment with user_sample_size=100 and movie_sample_size=5000\n",
      "actual_movies0\n",
      "recommended_movies10\n",
      "actual_movies5\n",
      "recommended_movies10\n",
      "actual_movies5\n",
      "recommended_movies10\n",
      "actual_movies10\n",
      "recommended_movies10\n",
      "actual_movies85\n",
      "recommended_movies10\n",
      "actual_movies23\n",
      "recommended_movies10\n",
      "actual_movies67\n",
      "recommended_movies10\n",
      "actual_movies27\n",
      "recommended_movies10\n",
      "actual_movies6\n",
      "recommended_movies10\n",
      "actual_movies123\n",
      "recommended_movies10\n",
      "actual_movies4\n",
      "recommended_movies10\n",
      "actual_movies77\n",
      "recommended_movies10\n",
      "actual_movies11\n",
      "recommended_movies10\n",
      "actual_movies9\n",
      "recommended_movies10\n",
      "actual_movies6\n",
      "recommended_movies10\n",
      "actual_movies8\n",
      "recommended_movies10\n",
      "actual_movies15\n",
      "recommended_movies10\n",
      "actual_movies4\n",
      "recommended_movies10\n",
      "actual_movies5\n",
      "recommended_movies10\n",
      "actual_movies19\n",
      "recommended_movies10\n",
      "actual_movies30\n",
      "recommended_movies10\n",
      "actual_movies9\n",
      "recommended_movies10\n",
      "actual_movies33\n",
      "recommended_movies10\n",
      "actual_movies4\n",
      "recommended_movies10\n",
      "actual_movies11\n",
      "recommended_movies10\n",
      "actual_movies44\n",
      "recommended_movies10\n",
      "actual_movies18\n",
      "recommended_movies10\n",
      "actual_movies4\n",
      "recommended_movies10\n",
      "actual_movies4\n",
      "recommended_movies10\n",
      "actual_movies57\n",
      "recommended_movies10\n",
      "actual_movies9\n",
      "recommended_movies10\n",
      "actual_movies9\n",
      "recommended_movies10\n",
      "actual_movies41\n",
      "recommended_movies10\n",
      "actual_movies25\n",
      "recommended_movies10\n",
      "actual_movies88\n",
      "recommended_movies10\n",
      "actual_movies8\n",
      "recommended_movies10\n",
      "actual_movies6\n",
      "recommended_movies10\n",
      "actual_movies26\n",
      "recommended_movies10\n",
      "actual_movies12\n",
      "recommended_movies10\n",
      "actual_movies33\n",
      "recommended_movies10\n",
      "actual_movies2\n",
      "recommended_movies10\n",
      "actual_movies144\n",
      "recommended_movies10\n",
      "actual_movies14\n",
      "recommended_movies10\n",
      "actual_movies19\n",
      "recommended_movies10\n",
      "actual_movies71\n",
      "recommended_movies10\n",
      "actual_movies22\n",
      "recommended_movies10\n",
      "actual_movies42\n",
      "recommended_movies10\n",
      "actual_movies10\n",
      "recommended_movies10\n",
      "actual_movies5\n",
      "recommended_movies10\n",
      "actual_movies37\n",
      "recommended_movies10\n",
      "actual_movies6\n",
      "recommended_movies10\n",
      "actual_movies6\n",
      "recommended_movies10\n",
      "actual_movies68\n",
      "recommended_movies10\n",
      "actual_movies54\n",
      "recommended_movies10\n",
      "actual_movies18\n",
      "recommended_movies10\n",
      "actual_movies17\n",
      "recommended_movies10\n",
      "actual_movies22\n",
      "recommended_movies10\n",
      "actual_movies16\n",
      "recommended_movies10\n",
      "actual_movies27\n",
      "recommended_movies10\n",
      "actual_movies33\n",
      "recommended_movies10\n",
      "actual_movies15\n",
      "recommended_movies10\n",
      "actual_movies19\n",
      "recommended_movies10\n",
      "actual_movies9\n",
      "recommended_movies10\n",
      "actual_movies3\n",
      "recommended_movies10\n",
      "actual_movies326\n",
      "recommended_movies10\n",
      "actual_movies37\n",
      "recommended_movies10\n",
      "actual_movies38\n",
      "recommended_movies10\n",
      "actual_movies6\n",
      "recommended_movies10\n",
      "actual_movies6\n",
      "recommended_movies10\n",
      "actual_movies55\n",
      "recommended_movies10\n",
      "actual_movies47\n",
      "recommended_movies10\n",
      "actual_movies44\n",
      "recommended_movies10\n",
      "actual_movies36\n",
      "recommended_movies10\n",
      "actual_movies68\n",
      "recommended_movies10\n",
      "actual_movies11\n",
      "recommended_movies10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual_movies11\n",
      "recommended_movies10\n",
      "actual_movies12\n",
      "recommended_movies10\n",
      "actual_movies26\n",
      "recommended_movies10\n",
      "actual_movies15\n",
      "recommended_movies10\n",
      "actual_movies207\n",
      "recommended_movies10\n",
      "actual_movies4\n",
      "recommended_movies10\n",
      "actual_movies79\n",
      "recommended_movies10\n",
      "actual_movies222\n",
      "recommended_movies10\n",
      "actual_movies10\n",
      "recommended_movies10\n",
      "actual_movies32\n",
      "recommended_movies10\n",
      "actual_movies5\n",
      "recommended_movies10\n",
      "actual_movies7\n",
      "recommended_movies10\n",
      "actual_movies146\n",
      "recommended_movies10\n",
      "actual_movies11\n",
      "recommended_movies10\n",
      "actual_movies44\n",
      "recommended_movies10\n",
      "actual_movies5\n",
      "recommended_movies10\n",
      "actual_movies16\n",
      "recommended_movies10\n",
      "actual_movies29\n",
      "recommended_movies10\n",
      "actual_movies47\n",
      "recommended_movies10\n",
      "actual_movies3\n",
      "recommended_movies10\n",
      "actual_movies15\n",
      "recommended_movies10\n",
      "actual_movies8\n",
      "recommended_movies10\n",
      "actual_movies7\n",
      "recommended_movies10\n",
      "actual_movies100\n",
      "recommended_movies10\n",
      "actual_movies46\n",
      "recommended_movies10\n",
      "Precision: 0.522, Recall: 1.0, F1: 0.6859395532194481, Memory Usage: 5792.6171875 MB\n",
      "Running experiment with user_sample_size=100 and movie_sample_size=20000\n",
      "actual_movies27\n",
      "recommended_movies10\n",
      "actual_movies21\n",
      "recommended_movies10\n",
      "actual_movies233\n",
      "recommended_movies10\n",
      "actual_movies28\n",
      "recommended_movies10\n",
      "actual_movies8\n",
      "recommended_movies10\n",
      "actual_movies6\n",
      "recommended_movies10\n",
      "actual_movies14\n",
      "recommended_movies10\n",
      "actual_movies89\n",
      "recommended_movies10\n",
      "actual_movies112\n",
      "recommended_movies10\n",
      "actual_movies7\n",
      "recommended_movies10\n",
      "actual_movies4\n",
      "recommended_movies10\n",
      "actual_movies8\n",
      "recommended_movies10\n",
      "actual_movies11\n",
      "recommended_movies10\n",
      "actual_movies30\n",
      "recommended_movies10\n",
      "actual_movies5\n",
      "recommended_movies10\n",
      "actual_movies5\n",
      "recommended_movies10\n",
      "actual_movies7\n",
      "recommended_movies10\n",
      "actual_movies71\n",
      "recommended_movies10\n",
      "actual_movies39\n",
      "recommended_movies10\n",
      "actual_movies36\n",
      "recommended_movies10\n",
      "actual_movies5\n",
      "recommended_movies10\n",
      "actual_movies59\n",
      "recommended_movies10\n",
      "actual_movies3\n",
      "recommended_movies10\n",
      "actual_movies10\n",
      "recommended_movies10\n",
      "actual_movies11\n",
      "recommended_movies10\n",
      "actual_movies10\n",
      "recommended_movies10\n",
      "actual_movies28\n",
      "recommended_movies10\n",
      "actual_movies38\n",
      "recommended_movies10\n",
      "actual_movies168\n",
      "recommended_movies10\n",
      "actual_movies27\n",
      "recommended_movies10\n",
      "actual_movies2\n",
      "recommended_movies10\n",
      "actual_movies15\n",
      "recommended_movies10\n",
      "actual_movies9\n",
      "recommended_movies10\n",
      "actual_movies16\n",
      "recommended_movies10\n",
      "actual_movies57\n",
      "recommended_movies10\n",
      "actual_movies23\n",
      "recommended_movies10\n",
      "actual_movies27\n",
      "recommended_movies10\n",
      "actual_movies26\n",
      "recommended_movies10\n",
      "actual_movies7\n",
      "recommended_movies10\n",
      "actual_movies22\n",
      "recommended_movies10\n",
      "actual_movies304\n",
      "recommended_movies10\n",
      "actual_movies10\n",
      "recommended_movies10\n",
      "actual_movies165\n",
      "recommended_movies10\n",
      "actual_movies13\n",
      "recommended_movies10\n",
      "actual_movies66\n",
      "recommended_movies10\n",
      "actual_movies20\n",
      "recommended_movies10\n",
      "actual_movies13\n",
      "recommended_movies10\n",
      "actual_movies3\n",
      "recommended_movies10\n",
      "actual_movies44\n",
      "recommended_movies10\n",
      "actual_movies41\n",
      "recommended_movies10\n",
      "actual_movies4\n",
      "recommended_movies10\n",
      "actual_movies3\n",
      "recommended_movies10\n",
      "actual_movies11\n",
      "recommended_movies10\n",
      "actual_movies16\n",
      "recommended_movies10\n",
      "actual_movies15\n",
      "recommended_movies10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5788/78349231.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Uruchamiamy eksperyment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         precision, recall, f1, memory_usage = run_experiment(\n\u001b[0m\u001b[0;32m    136\u001b[0m             \u001b[0mratings_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mratings_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mratings_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mcosine_sim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcosine_sim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5788/78349231.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[1;34m(ratings_train, ratings_test, cosine_sim, user_sample_size, movie_sample_size, top_n)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[1;32min\u001b[0m \u001b[0musers_sample\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mrecommended_movies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosine_sim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtop_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m# Filmy ocenione przez użytkownika w zbiorze testowym\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5788/78349231.py\u001b[0m in \u001b[0;36mget_recommendations\u001b[1;34m(user_id, ratings, cosine_sim, movies, top_n)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosine_sim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# Tworzymy profil użytkownika na danych treningowych\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0muser_profile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_user_profile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosine_sim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# Obliczamy podobieństwo profilu użytkownika do każdego filmu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5788/78349231.py\u001b[0m in \u001b[0;36mcreate_user_profile\u001b[1;34m(user_id, ratings, cosine_sim, movies)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mtotal_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrating\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrated_movies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'movieId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrated_movies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmovies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmovies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'movieId'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;31m# Zamiast cosine_sim[idx] * rating, możemy po prostu dodać cechy filmów pomnożone przez ocenę\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3447\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3448\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3449\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3451\u001b[0m         \u001b[1;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3502\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3503\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3504\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3506\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3626\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3627\u001b[0m         \"\"\"\n\u001b[1;32m-> 3628\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3629\u001b[0m         \u001b[1;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3613\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3615\u001b[1;33m         new_data = self._mgr.take(\n\u001b[0m\u001b[0;32m   3616\u001b[0m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3617\u001b[0m         )\n",
      "\u001b[1;32mg:\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    862\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 864\u001b[1;33m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    865\u001b[0m         return self.reindex_indexer(\n\u001b[0;32m    866\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, allow_fill, fill_value, **kwargs)\u001b[0m\n\u001b[0;32m    959\u001b[0m         \u001b[1;31m# Note: we discard fill_value and use self._na_value, only relevant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;31m#  in the case where allow_fill is True and fill_value is not None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         taken = algos.take(\n\u001b[0m\u001b[0;32m    962\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_na_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m         )\n",
      "\u001b[1;32mg:\\python\\python38\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(arr, indices, axis, allow_fill, fill_value)\u001b[0m\n\u001b[0;32m   1514\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1515\u001b[0m         \u001b[1;31m# NumPy style\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1516\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1517\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Eksperyment: Algorytm Content-based filtering próba 2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Wczytanie danych\n",
    "ratings = pd.read_csv(ml_rating_path)\n",
    "movies = pd.read_csv(ml_movies_path)\n",
    "tags = pd.read_csv(ml_tags_path)\n",
    "\n",
    "# Przygotowanie cech filmów: gatunki + tagi\n",
    "movies['genres'] = movies['genres'].fillna('')\n",
    "tags['tag'] = tags['tag'].fillna('')\n",
    "\n",
    "# Grupowanie tagów według movieId i łączenie ich w jeden ciąg\n",
    "tags_combined = tags.groupby('movieId')['tag'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# Łączenie danych\n",
    "movies = movies.merge(tags_combined, on='movieId', how='left')\n",
    "\n",
    "# Tworzenie cechy 'features' (gatunki + tagi)\n",
    "movies['features'] = movies['genres'] + ' ' + movies['tag']\n",
    "\n",
    "# Upewniamy się, że w kolumnie 'features' nie ma wartości NaN\n",
    "movies['features'] = movies['features'].fillna('')\n",
    "\n",
    "# Reprezentacja filmów jako wektory przy użyciu TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(movies['features'])\n",
    "\n",
    "# Obliczanie podobieństwa między filmami\n",
    "cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Podział danych na zbiór treningowy i testowy (np. 80% treningowe, 20% testowe)\n",
    "ratings_train, ratings_test = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "\n",
    "# Funkcja do tworzenia profilu użytkownika (na danych treningowych)\n",
    "def create_user_profile(user_id, ratings, cosine_sim, movies):\n",
    "    rated_movies = ratings[ratings['userId'] == user_id]\n",
    "    rated_movie_ids = rated_movies['movieId'].tolist()\n",
    "    \n",
    "    # Tworzymy profil jako ważoną średnią cech ocenionych filmów\n",
    "    weighted_features = np.zeros(tfidf_matrix.shape[1])  # Wektor z zerami o takim samym rozmiarze, jak cechy filmów\n",
    "    total_weight = 0\n",
    "    for movie_id, rating in zip(rated_movies['movieId'], rated_movies['rating']):\n",
    "        idx = movies[movies['movieId'] == movie_id].index[0]\n",
    "        \n",
    "        # Zamiast cosine_sim[idx] * rating, możemy po prostu dodać cechy filmów pomnożone przez ocenę\n",
    "        weighted_features += tfidf_matrix[idx].toarray().flatten() * rating  # Convert sparse matrix row to dense array\n",
    "        total_weight += rating\n",
    "    \n",
    "    if total_weight > 0:\n",
    "        weighted_features /= total_weight  # Normalizacja, aby uzyskać średnią ważoną\n",
    "    \n",
    "    return weighted_features\n",
    "\n",
    "# Funkcja do generowania rekomendacji na podstawie profilu użytkownika\n",
    "def get_recommendations(user_id, ratings, cosine_sim, movies, top_n=10):\n",
    "    # Tworzymy profil użytkownika na danych treningowych\n",
    "    user_profile = create_user_profile(user_id, ratings, cosine_sim, movies)\n",
    "    \n",
    "    # Obliczamy podobieństwo profilu użytkownika do każdego filmu\n",
    "    similarities = cosine_similarity([user_profile], tfidf_matrix)[0]\n",
    "    \n",
    "    # Sortujemy filmy po podobieństwie (najwyższe na początku)\n",
    "    similar_movie_indices = similarities.argsort()[-top_n-1:-1][::-1]  # Pomijamy już ocenione filmy\n",
    "    recommended_movie_ids = movies.iloc[similar_movie_indices]['movieId'].tolist()\n",
    "    \n",
    "    return recommended_movie_ids\n",
    "\n",
    "# Funkcja do obliczania metryk\n",
    "def calculate_metrics(recommended_movies, ratings_test):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for movie in recommended_movies:\n",
    "        # Sprawdzamy, czy film został oceniony przez użytkownika w zbiorze testowym\n",
    "        actual_ratings = ratings_test[ratings_test['movieId'] == movie]\n",
    "        \n",
    "        # Jeżeli film został oceniony przez użytkownika na 4 lub więcej, uznajemy go za interesujący\n",
    "        if not actual_ratings.empty:\n",
    "            user_rating = actual_ratings['rating'].iloc[0]\n",
    "            y_true.append(1 if user_rating >= 4 else 0)\n",
    "        else:\n",
    "            y_true.append(0)\n",
    "        \n",
    "        # Zawsze zakładamy, że rekomendacja jest pozytywna (1)\n",
    "        y_pred.append(1)\n",
    "\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Funkcja do przeprowadzenia eksperymentu\n",
    "def run_experiment(ratings_train, ratings_test, cosine_sim, user_sample_size=10, movie_sample_size=100, top_n=10):\n",
    "    # Tworzymy próbkę użytkowników\n",
    "    users_sample = ratings_train['userId'].drop_duplicates().sample(user_sample_size)\n",
    "    \n",
    "    # Generowanie rekomendacji dla użytkowników w zbiorze testowym\n",
    "    all_recommendations = []\n",
    "    all_actual_movies = []\n",
    "    \n",
    "    for user in users_sample:\n",
    "        recommended_movies = get_recommendations(user, ratings_train, cosine_sim, movies, top_n=top_n)\n",
    "        \n",
    "        # Filmy ocenione przez użytkownika w zbiorze testowym\n",
    "        actual_movies = ratings_test[ratings_test['userId'] == user]['movieId'].tolist()\n",
    "        \n",
    "        all_recommendations.extend(recommended_movies)\n",
    "        all_actual_movies.extend(actual_movies)\n",
    "\n",
    "    # Obliczanie metryk\n",
    "    precision, recall, f1 = calculate_metrics(all_recommendations, ratings_test)\n",
    "\n",
    "    # Mierzenie zużycia pamięci\n",
    "    process = psutil.Process()\n",
    "    memory_usage = process.memory_info().rss / (1024 * 1024)  # w MB\n",
    "\n",
    "    return precision, recall, f1, memory_usage\n",
    "\n",
    "# Przeprowadzanie eksperymentu\n",
    "user_sample_sizes = [10, 100, 1000]  # Liczba użytkowników\n",
    "movie_sample_sizes = [100, 5000, 20000]  # Liczba filmów\n",
    "\n",
    "# Pętla do uruchomienia eksperymentu dla różnych liczby użytkowników i filmów\n",
    "for user_sample_size in user_sample_sizes:\n",
    "    for movie_sample_size in movie_sample_sizes:\n",
    "        print(f\"Running experiment with user_sample_size={user_sample_size} and movie_sample_size={movie_sample_size}\")\n",
    "        \n",
    "        # Uruchamiamy eksperyment\n",
    "        precision, recall, f1, memory_usage = run_experiment(\n",
    "            ratings_train=ratings_train, ratings_test=ratings_test, \n",
    "            cosine_sim=cosine_sim, \n",
    "            user_sample_size=user_sample_size, \n",
    "            movie_sample_size=movie_sample_size\n",
    "        )\n",
    "\n",
    "        # Wyświetlanie wyników\n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}, Memory Usage: {memory_usage} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efb837f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
